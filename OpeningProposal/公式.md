Complex Gaussian Distribution & MMSE-Estimator (Bayes' rule)
$$
\mathbf{Y_k}(m)=R_{k}(m) \exp \left(j \cdot \theta_k(m)\right)
$$

$$
\mathbf{D}_{k}(m)=N_{k}(m) \exp \left(j \cdot \phi_{k}(m)\right)
$$


$$
p(N)=\frac{2 N}{\lambda_{d}} \exp \left(-\frac{-N^{2}}{\lambda_{d}}\right)
$$

$$
p(\mathbf{Y} | N, \phi)=\frac{1}{\pi \lambda_{x}} \exp \left(\frac{-\left|\mathbf{Y}-N e^{j \phi}\right|^{2}}{\lambda_{x}}\right)
$$

$$
p\left(N | \mathbf Y\right)=\frac{p\left(\mathbf Y | N\right) p(\mathbf Y)}{p\left(N\right)}
$$

$$
\hat{N}^{2}=E\left[N^{2} | \mathbf{Y}\right]
$$



LogErr
$$
\log \operatorname{Err}=\frac{10}{N L} \sum_{l=0}^{L-1} \sum_{k=0}^{N-1}\left|\min \left(0, \log _{10} \frac{\sigma_{ k}^{2}(l)}{\widehat{\sigma_{ k}^{2}}(l)}\right)\right|
$$

SegSNR
$$
\text { Seg.SNR }=\frac{10}{M} \sum_{m=0}^{M-1} \log _{10}\left(\frac{\sum_{n=N_{m}}^{N_{m}+N-1} s^{2}(n)}{\sum_{n=N_{m}}^{N_{m}+N-1}\{s(n)-\hat{s}(n)\}^{2}}\right)
$$



Mapping
$$
p\left(z_{i}\right)=\frac{\log \left(1+\rho\left(\frac{a\left(z_{i}\right)-a_{\text {base}}}{a_{\text {sat}}-a_{\text {base}}}\right)\right)}{\log (1+\rho)}
$$

Maximum likelihood
$$
\bar{\gamma}_{k}(n)=\alpha \bar{\gamma}_{k}(n-1)+(1-\alpha) \frac{\gamma_{k}(n)}{\beta}\\
\hat{\xi}_{k}(n)=\left\{\begin{array}{cc}{\bar{\gamma}_{k}(n)-1} & {\bar{\gamma}_{k}(n)-1 \geqslant 0} \\ {0} & {\text { otherwise }}\end{array}\right.
$$

IMCRA-$\xi$
$$
\begin{aligned} \hat{\xi}(k, \ell)=& \alpha G_{\mathrm{H}_{1}}^{2}(k, \ell-1) \gamma(k, \ell-1) \\ &+(1-\alpha) \max \{\gamma(k, \ell)-1,0\} \end{aligned}
$$

Decision-Directed Approach
$$
\begin{aligned} \hat{\xi}_{k}(n)=& \alpha G^{2}\left(\hat{\xi}_{k}(n-1)\right) \gamma_{k}(n-1) \\ &+(1-\alpha) P\left[\gamma_{k}(n)-1\right] \end{aligned}
$$

$$
G_{w}\left(\xi_{k}, \gamma_{k}\right)=\frac{\xi_{k}}{1+\xi_{k}}
$$

